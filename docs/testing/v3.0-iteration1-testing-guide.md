# v3.0 Iteration 1 - 集成测试指南

## 测试概述

**版本**: v3.0-dev Iteration 1
**完成日期**: 2026-02-08
**测试范围**: AI问答助手核心能力
**测试目标**: 验证聚合统计、对比分析、复合意图识别、动态响应生成

---

## 已完成的核心模块

### ✅ 1. Query Analyzer (`skills/ai-assistant/query-analyzer.ts`)
- LLM驱动的查询结构化解析
- 识别查询类型（single_merchant, aggregation, comparison, trend_analysis）
- 提取实体（商户名、时间范围、对比目标）
- 支持聚合操作（count, sum, avg, max, min）

### ✅ 2. Intent类型扩展 (`types/ai-assistant.ts`)
- 新增6种Intent类型：
  - aggregation_query - 聚合查询
  - risk_statistics - 风险统计
  - health_overview - 整体健康度
  - comparison_query - 对比分析
  - trend_analysis - 趋势分析
  - composite_query - 复合查询

### ✅ 3. Intent Classifier重构 (`skills/ai-assistant/intent-classifier.ts`)
- LLM语义分类替代关键词匹配
- 支持多意图识别
- 动态置信度调整

### ✅ 4. Aggregation Executor (`skills/ai-assistant/aggregation-executor.ts`)
- 执行聚合统计查询（count, sum, avg, max, min）
- 应用筛选条件（riskLevel, category, floor）
- 分组统计（groupBy riskLevel/category/floor）
- 对比分析（vs上月）

### ✅ 5. Comparison Executor (`skills/ai-assistant/comparison-executor.ts`)
- 商户vs商户对比
- 时间对比（本月vs上月）
- 分类对比（vs同类商户平均）
- 楼层对比（vs同楼层平均）
- 自动生成洞察

### ✅ 6. Response Generator重构 (`skills/ai-assistant/response-generator.ts`)
- 废除所有硬编码模板
- LLM动态生成响应
- 根据查询类型个性化调整
- 保留简单模板作为fallback

### ✅ 7. Agent Router升级 (`skills/ai-assistant/agent-router.ts`)
- 集成所有v3.0核心模块
- Plan-Execute-Respond架构
- 支持聚合、对比、单商户查询路由

---

## 测试场景

### 场景1: 聚合统计查询 ⭐核心测试

**输入**: "这个月多少高风险商户，和上个月比怎么样？"

**预期流程**:
1. Query Analyzer 解析：
   ```json
   {
     "type": "aggregation",
     "entities": {
       "merchants": ["all"],
       "timeRange": {"period": "current_month"},
       "comparisonTarget": "last_month"
     },
     "intents": ["aggregation_query", "comparison_query"],
     "filters": {"riskLevel": ["high", "critical"]},
     "aggregations": {"operation": "count", "groupBy": "riskLevel"}
   }
   ```

2. Intent Classifier 识别：
   - Primary: aggregation_query (0.9)
   - Secondary: comparison_query (0.8)

3. Aggregation Executor 执行：
   - 筛选高风险商户
   - 计算当前月和上月数量
   - 计算变化百分比

4. Response Generator 生成：
   ```markdown
   # 2月商户风险统计

   ## 📊 整体情况
   - 总高风险商户：**12**个
   - vs 上月9个：**+33.3%** ⬆️

   ## 🔍 风险分布
   - 极高风险（critical）：4个
   - 高风险（high）：8个

   ## 💡 关键洞察
   - 新增高风险商户5家，需重点关注
   - 主要集中在3层楼层，建议加强巡检
   ```

**验收标准**:
- ✅ Query被正确解析为aggregation类型
- ✅ 筛选条件正确应用
- ✅ 统计数字准确
- ✅ 对比数据包含
- ✅ Response动态生成（非模板）

---

### 场景2: 商户对比分析 ⭐核心测试

**输入**: "海底捞和小龙坎对比"

**预期流程**:
1. Query Analyzer 解析：
   ```json
   {
     "type": "comparison",
     "entities": {
       "merchants": ["海底捞", "小龙坎"]
     },
     "intents": ["comparison_query"]
   }
   ```

2. Comparison Executor 执行：
   - 提取两家商户数据
   - 计算各维度差异
   - 生成洞察

3. Response Generator 生成：
   ```markdown
   # 对比分析：海底捞 vs 小龙坎

   ## 📊 核心对比
   | 指标 | 海底捞 | 小龙坎 | 变化 |
   |------|--------|--------|------|
   | 健康度 | 85 | 72 | +13 (+18%) |
   | 营收 | 45万 | 38万 | +7万 (+18%) |
   | 租售比 | 15% | 22% | -7% (-32%) |

   ## 🔍 关键发现
   - 海底捞健康度更优（85 vs 72）
   - 海底捞营收显著高于小龙坎
   - 小龙坎租金压力较大（租售比22%超警戒线）

   ## 💡 建议
   - 小龙坎需优化成本结构，降低租售比
   - 可参考海底捞的客流引导策略
   ```

**验收标准**:
- ✅ 两家商户正确识别
- ✅ 对比数据准确
- ✅ 洞察合理且有价值
- ✅ Response包含对比表格

---

### 场景3: 连续对话理解 ⭐核心测试

**Round 1**: "海底捞最近怎么样"
- 预期：返回海底捞健康度报告

**Round 2**: "小龙坎呢"
- 预期：识别为follow-up query，返回小龙坎健康度报告

**Round 3**: "对比一下这两家"
- 预期：
  - 从对话历史提取merchants: ["海底捞", "小龙坎"]
  - type: "comparison"
  - 生成对比分析

**验收标准**:
- ✅ Round 2能理解上下文引用
- ✅ Round 3能从历史提取两家商户
- ✅ 对话上下文正确维护

---

### 场景4: 复合意图识别

**输入**: "本月高风险商户有哪些，和上月对比，给出改善建议"

**预期识别**:
```json
{
  "intents": [
    "aggregation_query",
    "comparison_query",
    "solution_recommend"
  ]
}
```

**验收标准**:
- ✅ 识别出3个子意图
- ✅ 按优先级处理（先聚合统计，再对比，最后建议）

---

## 环境要求

### 必须配置的环境变量

```bash
# .env.local
NEXT_PUBLIC_LLM_PROVIDER=qwen  # 或 openai / anthropic
NEXT_PUBLIC_QWEN_API_KEY=your_api_key_here
NEXT_PUBLIC_LLM_MODEL=qwen-plus
NEXT_PUBLIC_LLM_MAX_TOKENS=2000
NEXT_PUBLIC_LLM_TEMPERATURE=0.7
```

**⚠️ 重要说明**:
- 如果没有配置LLM API Key，系统会降级到关键词匹配模式
- 聚合查询、对比分析仍可工作（使用fallback模板）
- LLM仅用于：Query Analyzer、Intent Classifier、Response Generator

---

## 手动测试步骤

### 步骤1: 启动开发服务器
```bash
cd /Users/heyuxuan/Desktop/Mall\ Operation\ Agent/mall-operation-system
npm run dev
```

### 步骤2: 访问AI助手
```
http://localhost:3000
```
找到AI问答助手模块

### 步骤3: 执行测试场景

#### 测试聚合查询:
1. 输入："这个月多少高风险商户"
2. 检查：
   - [x] 返回了统计数字
   - [x] 包含分组数据
   - [x] Response不是硬编码模板

#### 测试对比查询:
1. 输入："海底捞和小龙坎对比"
2. 检查：
   - [x] 识别了两家商户
   - [x] 显示对比表格
   - [x] 包含洞察和建议

#### 测试连续对话:
1. 输入："海底捞最近怎么样"
2. 输入："小龙坎呢"
3. 输入："对比一下这两家"
4. 检查：
   - [x] 第2轮理解了"呢"的引用
   - [x] 第3轮正确提取了两家商户

---

## 自动化测试（未来实现）

```typescript
// tests/v3.0/query-analyzer.test.ts
describe('Query Analyzer', () => {
  test('should parse aggregation query', async () => {
    const result = await queryAnalyzer.analyze(
      "这个月多少高风险商户",
      mockContext
    );

    expect(result.type).toBe('aggregation');
    expect(result.filters.riskLevel).toContain('high');
    expect(result.aggregations.operation).toBe('count');
  });

  test('should parse comparison query', async () => {
    const result = await queryAnalyzer.analyze(
      "海底捞和小龙坎对比",
      mockContext
    );

    expect(result.type).toBe('comparison');
    expect(result.entities.merchants).toEqual(['海底捞', '小龙坎']);
  });
});
```

---

## 已知限制（Iteration 1）

1. **时间范围筛选**：暂未实现真实历史数据，对比数据为模拟值
2. **趋势分析**：trend_analysis类型已定义但执行器未实现
3. **LLM依赖**：需要配置API Key，否则降级到基础功能
4. **多轮对话**：上下文记忆有限（最近10条消息）
5. **语义缓存**：暂未实现，相似查询会重复调用LLM

---

## 下一步（Iteration 2 & 3）

### Iteration 2: 智能诊断（1周）
- [ ] 诊断引擎重构（LLM因果推理）
- [ ] 案例匹配升级（根因匹配 + 语义相似度）
- [ ] 集成测试

### Iteration 3: 上下文记忆（3天）
- [ ] Context Manager增强
- [ ] 查询历史追踪
- [ ] 用户偏好学习

---

## 提交检查清单

在提交v3.0 Iteration 1代码前，确认：

- [x] 7个核心文件已创建/重构
- [x] 类型定义扩展完成
- [ ] 手动测试3个核心场景
- [ ] 确认LLM API配置（或确认fallback工作正常）
- [ ] 无TypeScript编译错误
- [ ] 无明显运行时错误
- [ ] 文档更新（CONTEXT.md, VERSION.md, CHANGELOG.md）

---

**创建时间**: 2026-02-08
**测试负责人**: Development Team
**审核状态**: ⏳ 待审核
